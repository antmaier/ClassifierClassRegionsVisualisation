{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from Modules import Autoencoder\n",
    "from Modules import LinearAutoencoder\n",
    "from LossFunctions import tan_square, log_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested to train autoencoders, so we flatten the 2dim of the images and\n",
    "# squeeze the single channel dimension\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: torch.squeeze(x)),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x, start_dim=-2))])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Train and test data tensors loaded on the GPU\n",
    "# train_data = train_dataset.data.flatten(start_dim=-2).to(device)\n",
    "# test_data = test_dataset.data.flatten(start_dim=-2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, _ in train_dataloader:\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransformer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # https://stackoverflow.com/questions/60908827/why-pytorch-nn-module-cuda-not-moving-module-tensor-but-only-parameters-and-bu\n",
    "        self.positional_encoding = nn.Parameter(torch.rand((28), requires_grad=True)) # TODO see if requires_grad=True is needed here\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=28, \n",
    "            nhead=1, \n",
    "            num_encoder_layers=3, \n",
    "            num_decoder_layers=3, \n",
    "            batch_first=True) # https://discuss.pytorch.org/t/why-is-sequence-batch-features-the-default-instead-of-bxsxf/8244\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Takes a batch of 28*28 pictures (N,28,28) # TODO verifier que c'est pas (N,1,28,28) que donne le dataloader\n",
    "        We want to have (N,S,E)=(N,28,28), i.e. each row is a 'token' and the whole picture is a sentence.\"\"\"\n",
    "        input = torch.add(input, self.positional_encoding) # picture += positional encoding\n",
    "        # input = self.flatten(input) # (N,28,28) -> (N,784)\n",
    "        # input = torch.unsqueeze(input, 2) # (N,784) -> (N,784,1)\n",
    "        input = torch.squeeze(input) # TODO lié au TODO d'en haut (N,1,28,28)->(N,28,28)\n",
    "        output = self.transformer(input, input)\n",
    "        # output = torch.reshape(output, input.shape) # (N,1,784) -> (N,28,28)\n",
    "        return output\n",
    "\n",
    "# identity_transformer = IdentityTransformer().to(device)\n",
    "\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(identity_transformer.parameters(), lr=1e-4) # TODO train learning rate during training phase r adjust it \n",
    "# https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(dim_sequence=28*28, dim_bottleneck=2, dim_positional_encoding=2, num_heads=2, num_layers=2).to(device)\n",
    "# linear_autoencoder = LinearAutoencoder(dim_input=28*28, dim_bottleneck=2, step= 10, activation_function='ReLU').to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "# loss_function = log_product\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "# TODO tellement de trucs à fine-tuner ici..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(dataloader: DataLoader, model, loss_function, optimizer):\n",
    "    \"\"\"Right now, when iterated over, the dataloader returns a data point AND a label. \n",
    "    TODO faire en sorte que le dataloader soit composé que des images, sans les labels.\"\"\"\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_function(pred, X)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_autoencoder(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, _ in dataloader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, X).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def train_linear_autoencoder(data, model, loss_function, optimizer):\n",
    "    pred = model(data)\n",
    "    loss = loss_function(pred, data)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"Train loss:\", loss)\n",
    "\n",
    "def test_linear_autoencoder(data, model, loss_function):\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, data)\n",
    "\n",
    "    print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear autoencoder\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(\"Epoch:\", t)\n",
    "    train_linear_autoencoder(train_data, linear_autoencoder, loss_function, optimizer)\n",
    "    test_linear_autoencoder(test_data, linear_autoencoder, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_autoencoder(train_dataloader, autoencoder, loss_function, optimizer)\n",
    "    test_autoencoder(test_dataloader, autoencoder, loss_function)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "fig, axs = plt.subplots(n, 2, figsize=(2,5))\n",
    "for i in range(n):\n",
    "    # Input\n",
    "    random_index = np.random.randint(len(test_data))\n",
    "    img, label = test_data[random_index]\n",
    "    ax = axs[i, 0]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.axis(\"off\")\n",
    "    if i == 0: ax.set_title('Input')\n",
    "\n",
    "    # Output\n",
    "    input_image = img.to(device).squeeze().flatten(start_dim=-2)\n",
    "    output_image = autoencoder(input_image)\n",
    "    output_image = output_image.reshape(img.shape)\n",
    "\n",
    "    ax = axs[i, 1]\n",
    "    ax.imshow(output_image.cpu().detach().numpy().squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    if i == 0: ax.set_title('Output')\n",
    "plt.subplots_adjust(wspace=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO faire un environnement \"try\" ou quand on quitte l'environnement on enregistre le modèle dans l'état actuel, la training curve, etc\n",
    "# vérifier que si Windows décide d'update il quitte python de façon clean et lui laisse le temps d'enregistrer et tout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del(X)\n",
    "del(y)\n",
    "del(autoencoder)\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Emergence')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b1d9945a33258b0ffd7aeaf6809be58234033e79986f5ef0464e80e152d3eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
